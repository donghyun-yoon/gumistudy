# Chapter 10. 가상 메모리(Virtual Memory)

[가상 메모리](#chapter-10-가상-메모리virtual-memory)
- [Chapter 10. 가상 메모리(Virtual Memory)](#chapter-10-가상-메모리virtual-memory)
  - [1. 가상메모리(Virtual Memory)](#1-가상메모리virtual-memory)
    - [1-1. 가상메모리란?](#1-1-가상메모리란)
    - [1-2. Paging 기법](#1-2-paging-기법)
    - [1-3. 페이지테이블(Page Table)](#1-3-페이지테이블page-table)
    - [1-4. Multilevel Page Table](#1-4-multilevel-page-table)
  - [2. 요구 페이징(Demand Paging)](#2-요구-페이징demand-paging)
    - [2-1. 요구페이징이란?](#2-1-요구페이징이란)
    - [2-2. Valid-Invalid Bit](#2-2-valid-invalid-bit)
    - [2-3. Page Fault](#2-3-page-fault)
    - [2-4. 유효 접근 시간(Effective Access Time)](#2-4-유효-접근-시간effective-access-time)
  - [3. 페이지 교체(Page Replacement)](#3-페이지-교체page-replacement)
    - [3-1. Victim Page(희생양 페이지)](#3-1-victim-page희생양-페이지)
    - [3-2. 페이지 교체 알고리즘(Page Replacement Algorithm)](#3-2-페이지-교체-알고리즘page-replacement-algorithm)
  - [4. 프레임 할당(Allocation of Frames)](#4-프레임-할당allocation-of-frames)
    - [4-1. 할당 방법](#4-1-할당-방법)
    - [4-2. Global VS Local Replacement](#4-2-global-vs-local-replacement)
  - [5. 스레싱(Trashing)](#5-스레싱trashing)
    - [5-1. Working Set Model](#5-1-working-set-model)
    - [5-2. Page-Fault Frequency(PFF)](#5-2-page-fault-frequencypff)

<br/>
<br/>

## 1. 가상메모리(Virtual Memory)

### 1-1. 가상메모리란?

메인 메모리의 크기가 한정되어 있으므로 물리적인 메모리 크기보다 크기가 큰 프로세스를 실행시킬 수 없다. 예로 100MB 메인 메모리에서 200MB 크기의 프로세스를 실행할 수 없게 되는 것이다.
그렇다면 메인 메모리보다 크기가 큰 프로세스를 실행시키고 싶으면 어떻게 해야 할까? 단순히 메인 메모리가 더 큰 컴퓨터를 사용해야하는가? 이런 방법은 매우 비효율적일 것이다. 그래서 나온 방법이 바로 `가상 메모리`이다.

프로세스의 모든 코드는 항상 필요한 것이 아니다. 오류 처리하는 부분이나 필요 없는 배열 부분은 실제로 프로세스가 잘 동작한다면 필요 없는 부분이 된다. 따라서 `프로세스는 필요한 부분만 메모리에 올림으로써 메인 메모리에 올라가는 프로세스의 크기`를 줄인다.
프로세스 이미지를 모두 메모리에 올릴 필요가 없는 것이다. 동적 적재와 비슷한 개념이라고 알 수 있다.

따라서 다음과 같은 특징이 있다.
- 장점
  - 사용자 프로그램이 물리 메모리보다 커져도 된다. 즉, 메모리 크기의 제약으로부터 자유로워진다.
  - 각 사용자 프로그램이 더 작은 메모리를 차지하므로 더 많은 프로그램을 동시에 수행할 수 있다. 이에 따라 응답시간은 늘어나지 않으면서 CPU 이용률과 처리율이 높아진다.
  - 프로그램을 메모리에 올리고 스왑하는데 필요한 입/출력 횟수가 줄어든다. 따라서 프로그램들이 보다 빨리 실행된다.
  - 가상메모리 파일의 공유를 쉽게 해주고 공유 메모리 구현을 가능하게 한다.
  - 프로세스 생성을 효율적으로 처리할 수 있는 메커니즘도 제공한다.

- 단점
  - 구현이 어렵고, 잘못 사용시 성능이 현저히 저하될 수 있다.

<br/>

![](https://t1.daumcdn.net/cfile/tistory/22430F4E590E8ADA1C)

<br/>

### 1-2. Paging 기법

가상메모리 기술이 동작하기 위해서는 2가지 이슈가 있다.
1. 가상 메모리를 물리 메모리에 매핑시키는 **Address Translation**
2. 가상 공간에 대한 관리 이슈

이러한 Virtual Memory 와 Physical Memory 의 매핑을 위한 기술로 Paging 기법이 사용된다.

페이징 기법은 컴퓨터가 메인 메모리에서 사용하기 위해 데이터를 저장하고 검색하는 메모리 관리 기법이다.
페이징 기법을 통해 컴퓨터의 물리적 메모리는 연속적으로 할당되어 존재할 필요가 없으며, 반대로 연속적으로 존재하지 않는 물리적 메모리라도 페이징 기법을 통해 연속적으로 존재하는 것처럼 이용될 수 있다.

페이징 방식에서는 가상 메모리 상의 주소 공간을 일정한 크기로 분할한다. 
주소공간은 페이지 단위로 나뉘어져있으며 실제 기억공간은 페이지 크기와 같은 프레임으로 나누어 사용한다.

 - Frame : 물리 메모리를 일정된 한 크기로 나눈 블록
 - Page : 가상 메모리를 일정된 한 크기로 나눈 블록

이 때 Frame 과 Page 의 크기는 동일하게 관리된다.
페이지의 크기는 시스템에 따라 다르며 크기가 작으면 메모리를 단편화하기 쉬워지지만 페이지의 갯수가 많아지기 때문에 페이지 단위의 입출력이 자주 발생하게 된다.

페이지가 하나의 프레임을 할당받으면, 물리 메모리에 위치하게 된다.
프레임을 할당받지 못한 페이지들은 외부저장장치에 저장되며, 마찬가지로 프레임과 같은 크기 단위로 관리된다.

<br/>

### 1-3. 페이지테이블(Page Table)

페이징 기법에서 페이지는 페이지테이블(Page Table) 이라는 자료구조 형태로 관리된다.
Page Table 은 프로세스의 페이지 정보를 저장하고 있으며, 하나의 프로세스는 하나의 페이지 테이블을 가진다.
Page table 은 Index 를 키로 해당 페이지에 할당된 메모리(Frame)의 시작 주소를 Value 로 저장하고 있다.

페이지 테이블 엔트리(Page Table Entry)는 페이지 테이블의 레코드를 말한다.
PTE 의 각 필드에는 다음 내용들이 기록된다.

 - 페이지 기본 주소(Page base address)
 - 플래그 비트(Flag bit)
   - Accessed bit : 페이지에 대한 접근이 있었는지를 나타낸다.
   - Dirty bit : 페이지의 내용에 변경이 있었는지를 나타낸다.
   - Present bit : 현재 페이지에 할당된 프레임이 있는지를 나타낸다.
   - Read/Write bit : 읽기/쓰기에 대한 권한을 표시한다.

페이징 기법에서 동적 주소 변환 과정은 다음과 같다.
1. 수행 중인 프로세스가 가상주소를 참조한다.
2. 페이징 기법을 통해 페이지 p가 페이지 프레임 f에 있음을 알아낸다.
3. r(실주소) = f(페이지 프레임) + d(오프셋)를 구해낸다.

위와 같은 방식으로 페이지 테이블은 Virtual Memory 에서 Physical Memory 를 참조가능하도록 지원한다.

![](https://mblogthumb-phinf.pstatic.net/20130625_89/jevida_1372138229660y6nYl_PNG/2.png?type=w2)

페이지 테이블은 사용을 위해서 메모리에 존재해야 하지만, 그렇게 되면 메모리 접근에 있어서 중복 호출이 일어나므로(페이지 테이블에 한번, 페이지테이블을 통한 실제 메모리에 한번), 대게 MMU(Memory Management Unit) 의 지원을 받아 매핑시키게 된다.

<br/>

### 1-4. Multilevel Page Table

![](https://t1.daumcdn.net/cfile/tistory/995C7D345C1B85B708)

Page table entry들을 보다 효율적으로 운영하기 위해, 단계별로 Page table을 제작한 것을 `Multilevel Page Table`이라고 한다.
보통 2~3개의 Page table로 이루어져 있다.
2nd page table의 크기는 Page Frame의 크기와 동일한 4Kbyte를 가지게 된다.
3개의 page table을 운영하게 되면 무려.... 2^20의 page table entry 항목들이 가지게 된다.

<br/>
<br/>

## 2. 요구 페이징(Demand Paging)

### 2-1. 요구페이징이란?

우선 우리가 실행을 시키고자 하는 프로세스들을 `페이징` 과정을 먼저 실행한다. 메인 메모리의 외부 단편화 문제를 해결하여 메모리 낭비를 줄이는 데 페이징을 사용하면 매우 효율적이기 때문이다.

따라서 페이징 과정을 거쳐 특정 단위인 페이지 단위로 프로세스를 자른다. 그러면 여기서 페이지들마다 필요한 부분과 필요 없는 부분으로 나눌 수 있다. 여기서 프로세스의 이미지를 backing store에 저장한다.
backing store는 swap device로 하드웨어 부분인데 페이지를 임시로 보관하는 공간이다.
프로세스는 페이지의 조합이기 때문에 `필요한 페이지만 메모리`에 적재를 하면 많은 메모리의 낭비를 막고 우리가 필요한 프로세스들을 모두 메인 메모리에서 실행을 시킬 수 있게 되는 것이다. 이를 `요구 페이징`이라고 한다.

![](https://postfiles.pstatic.net/20130626_77/jevida_1372223864035VIz0Y_PNG/1.png?type=w3)

요구 페이징은 일부 스와핑 기법과 유사하다. 프로세스를 실행하고 싶으면메모리로 읽어 들이며 이때 전체 프로세스를 읽어오지 않고 lazy swapper를 사용한다. lazy swapper는 그 페이지가 필요하지 않는 한 메모리에 적재 되지 않는다.

<br/>

### 2-2. Valid-Invalid Bit

![](https://user-images.githubusercontent.com/34755287/57119450-47043400-6da5-11e9-8810-c6a981a1d689.png)

위 그림은 요구 페이징의 모습이다. 두 프로세스 P1, P2는 각각 필요한 페이지만 메모리에 할당하였다. 여기서 위 그림의 테이블은 P1이 수행 중일 때의 페이지 테이블이다.
기존의 페이지 테이블과 다른 점은 valid bit 가 추가되었다. 이는 현재 메모리에 페이지가 있는지 없는지를 나타내는 비트이다. 현재 페이지가 메모리에 있다면 1, 없다면 0값을 갖는다.

만약, CPU에서 P1의 3번째 페이지에 접근하는데, valid bit값이 0이다. 그러면 CPU에 인터럽트 신호를 발생하여 운영체제 내부의 ISR로 점프한다. 여기서 디스크 내부의 프로세스 P1에 있는 2번째 페이지를 메모리에 할당하는 작업을 처리한다.

![](https://user-images.githubusercontent.com/34755287/57119451-47043400-6da5-11e9-9ca3-d0b250683bf0.png)

위 그림은 P1의 3번째 페이지를 메모리에 올린 후 모습이다.

Page Fault 가 발생한 경우, 해당 프레임을 메인 메모리에 올린 뒤, 페이지 테이블에서 해당 페이지의 Valid-Invalid Bit 를 1로 설정해준다.


<br/>

### 2-3. Page Fault

만약 오류가 발생한다면 오류를 제어할 수 있는 코드를 실행해야한다. CPU에서 해당 메모리를 가져오라고 논리 주소를 보냈는데 페이지 테이블에서 접근하려는 페이지가 메모리에 없다고 표시가 되어 있다.
이는 valid 비트 필드에 의해서 결정된다. 그러면 Backing store에서 해당 페이지를 가져와야한다. 이를 수행하기 위해서 CPU는 잠시 하는 일을 멈추고 운영체제가 나서서 Backing store를 뒤져 필요한 페이지를 메모리에 적재하게 된다.
그리고 valid 비트를 올라와 있다고 바꾸어준다. 이런 현상을 페이지 결함, 페이지 부재(Page Fault)라고 부른다.

- Page Fault 의 신호는 크게 2 종류로 나뉜다.
  - 메인 메모리에 없어서, 이를 가상 메모리에서 메인 메모리로 적재하라는 신호
  - 유효하지 않은 페이지 넘버 접근 신호. 이 신호는 그냥 무시해버린다.

<br/>

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F3MDND%2FbtqzkQXWwnT%2FHnW1LS7RrayvpvoWqjslDK%2Fimg.png)

```
위 그림은 page fault가 발생했을 때 처리하는 과정을 나타낸 것이다.
1. 해당 페이지가 메모리에 있는지 valid bit를 확인한다.
2. valid bit가 0이라면 CPU에 인터럽트 신호를 보내어 운영체제 내부 해당 ISR로 점프한다.
3. 해당 ISR에서 backing store(디스크)를 탐색하여 해당 프로세스의 페이지를 찾는다.
4. 해당 페이지를 비어있는 프레임에 할당한다.
5. 페이지 테이블을 갱신한다.(프레임 번호 설정, valid bit 1로 변경)
6. 다시 명령어로 돌아가서 실행한다.
```

<br/>

~~~
요구 페이징을 할 때 두 가지의 종류가 있다.
1. pure demand paging : 처음부터 모든 페이지를 적재시키지 않고 CPU가 요구할 때 valid를 바꾸어 페이지를 적재하는 방법
2. prepaging 기법 : 우선 필요할 것 같은 페이지를 적재시키고 필요할 때 다른 페이지를 적재시키는 방법

pure 기법을 사용하면 페이지를 요구할 때만 메모리에 적재하므로 메모리의 낭비는 매우 줄일 수 있다. 하지만 요구에 의해 앞선 페이지 부재의 현상을 처리 하려고 하면 많은 부담이 발생한다.
이에 반해 미리 올라와져 있는 prepaging은 처리하는 속도는 빠르겠지만 메모리가 낭비될 수 있도 있다.

Swapping VS Demanding Paging
Swapping와 Demanding Paging의 공통점은 둘 다 메모리와 backing store 사이를 서로 오고 가는 기능을 수행하지만, Swapping은 프로세스 단위로 이동하고 Demanding Paging은 페이지 단위로 이동하는 차이점이 있다.
~~~

<br/>
<br/>

### 2-4. 유효 접근 시간(Effective Access Time)

Demending Paing은 페이지 테이블에 해당 페이지가 없으면 backing store에서 메모리로 가져오는 과정이 있으므로, 페이지 테이블에 해당 페이지가 있을 때와 없을 때 시간 차이가 발생한다.
이러한 시간 차이를 고려하여 평균적으로 어느정도 소요되는지 계산하는 것을 유효 접근 시간이라 한다.

- p: 페이지 부재 확률(probability of a page fault = page fault rate)
- Tm: 메모리를 읽는 시간
- Tp: Page fault가 발생했을 때 소요되는 시간(대부분 backing store(하드디스크)를 읽는 시간이 차지한다.)
- `T = (1-p)Tm + pTp`
- `EAT(Effective Access Time) = (1-p) * (메모리 접근시간) + p * (page fault overhead + swap in-out + restart overhead)`

예제를 살펴보자
- Tm = 200nsec (DRAM)
- Tp = 8msec (seek time + rotational delay + transfer time)
- T = (1-p) 200 + p 8,000,000 = 200 + 7,999,800 * p
- p = 1/1,000 => T = 8.2usec (40배 정도 느림)
- p = 1/399,990 => T = 220nsec (10% 정도 느림)

위의 예제를 보았을 때, page fault는 매우 적은 확률로 발생해야 효율적이다.
그러면 현실적으로 페이지 부재는 어느정도로 발생할까? 이는 지역성의 원리(Locality of reference)로 인해 페이지 부재 확률은 매우 낮다.
지역성의 원리는 '메모리 접근은 시간적 지역성과 공간적 지역성을 가진다'는 의미이다.

- 시간적 지역성: CPU는 어느 메모리 공간을 읽은 후, 시간이 지나도 그 공간을 다시 읽을 확률이 매우 높다는 것을 말한다.
  - 대표적인 예로 반복문이 있다. 반복문은 하나의 코드 공간을 여러 번 읽는다.
- 공간적 지역성: CPU가 메모리 공간을 읽을 때는 인접한 범위 내에서 읽는다는 의미이다.
  - 프로그램은 대부분 절차적인 순서로 구현되어 있어 순서대로 읽는 경우가 빈번하다.

이와 같이 페이지 부재가 현실적으로 발$$생할 확률은 매우 낮으므로 예제와 같이 40배로 느려지는 일을 거의 없다.
하지만 40배가 느려질 수 있다는 것으로 Page fault 가 최대한 안 일어나게, Out 시킬 페이지를 `잘` 골라야 한다.
따라서, 이슈를 잘 고를 수 있는 Page Replacement가 중요하다.

<br/>
<br/>

## 3. 페이지 교체(Page Replacement)

요구 페이징은 요구되어지는 페이지만 backing store에서 가져와 메인 메모리에 적재하는 방법이다. 필요한 페이지만 메인 메모리에 올리므로 메모리의 낭비를 줄이는 방법으로 사용되었다.
valid 비트를 추가한 페이지 테이블과 필요하지 않은 페이지를 보관하는 backing store를 가지고 기능을 수행할 수 있다.
하지만 프로그램 실행이 계속 진행되게 되면 요구 페이지가 늘어나게 되고 언젠가는 메모리가 가득 차게 될 것이다(memory full).
여기서 다른 프로그램이 새로 실행되거나 실행중인 프로세스가 다른 페이지를 요구한다면 `이미 메모리에 있는 페이지 중 하나를 다시 backing store에 보내고(page-out), 새로운 페이지를 메모리에 올려야한다.(page-in) 이를 페이지 교체라고 한다.`
여기서 backing store로 page-out이 된 페이지를 victim page 라고 한다.

<br/>

### 3-1. Victim Page(희생양 페이지)

희생양 페이지는 어떤 페이지로 하는 것이 좋을까? 먼저 생각할 수 있는 것은 메모리에 올라가 있는 페이지 중 CPU에 수정(modify)되지 않는 페이지를 고르는 것이 효율적으로 보인다.
수정되지 않은 페이지는 page-out이 될 때 backing store에 쓰기(write) 연산을 할 필요가 없기 때문이다.
backing store는 읽는 시간도 느리지만, 거기에 더해 쓰기 작업까지 한다면 더욱 비효율적일 것이다.

그러면 해당 페이지가 수정되었는지 안되었는지를 판단할 수 있어야 하는데, 이를 위해 페이지 테이블에 modified bit(=dirty bit)를 추가하여 이를 검사한다.
해당 페이지가 수정되었다면 이 비트를 1로 두고, 수정되지 않으면 0으로 둔다. 이를 이용해서 victim page는 최대한 수정되지 않은 페이지를 선택한다.

![](https://user-images.githubusercontent.com/34755287/57119453-479cca80-6da5-11e9-83e7-cd46f595422d.png)

위 그림은 modified bit를 추가한 페이지 테이블의 모습이다. 여기서 수정되지 않은 페이지는 0, 2, 3번 3개의 페이지가 존재하는데 이 중에서는 어떤 페이지를 선택해야 할까?

제일 간단한 방법은 랜덤하게 선택하는 것이지만, 이는 성능을 보장할 수 없다. 그 다음은 가장 먼저 메모리에 올라온 페이지를 희생양 페이지로 선택하는 것이다.
이는 아주 유명한 FIFO(First-In First-Out) 방식이다. 이 외에도 여러가지 방법이 존재한다.

여러 Page Replacement 알고리즘들을 소개하기 앞서, 먼저 이 알고리즘들의 성능 평가 하기 위한 Page Reference String이라는 개념을 먼저 알아야 한다.
그림으로 설명하는게 더 빠를듯 하다.

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbTS4IM%2FbtqzlEibObS%2FkLz3pNGS6zdFQaGWmVZhw1%2Fimg.png) 출처 : http://contents.kocw.or.kr/KOCW/document/2013/kyungsung/yangheejae/os05.pdf

즉, 위 프로세스 실행에서 참조한 페이지는 순서대로 1, 4, 6, 1, 6 이다. 이를 Page reference string 이라고 한다. 앞으로 주소 단위가 아닌 이 String 기준으로 인풋을 받아 알고리즘을 비교한다.

<br/>

### 3-2. 페이지 교체 알고리즘(Page Replacement Algorithm)

1. 최적 페이지 교체(Optimal Page Replacement)
   - 앞으로 가장 오랫동안 사용하지 않을 페이지를 교체하는 기법.
   - 미래에 어떤 페이지가 어떠한 순서로 참조될지 미리 알고있다는 전재하에 알고리즘을 운영하므로 현실적으로 구현이 어렵다.
   - 페이지 부재율이 가장 낮은 효율적인 알고리즘이다.
    
      ![](https://t1.daumcdn.net/cfile/tistory/265B26335916A03F39) 

<br/>

2. FIFO(First-In-First-Out) 알고리즘
   - 페이지 교체시 물리적 메모리에 가장 먼저 올라온 페이지를 우선적으로 내쫓는다.
   - 페이지의 향후 참조 가능성을 고려하지 않고, 물리적 메모리에 들어온 순서대로 내쫓을 대상을 선정하기때문에 비효율적인 상황이 발생할 수 있다.
   - 빌레이디의 모슨(Belady's Anomaly)현상이 발생할 수 있다.
   - (빌레이디 모순 현상 : 페이지 프레임 수가 많으면 페이지 부재수가 줄어드는 것이 일반적이지만, 페이지 프레임수를 증가시켰음에도 페이지 부재가 더 많이 일어나는 현상을 의미)

      ![](https://t1.daumcdn.net/cfile/tistory/256403335916A03E18) 

<br/>

3. LRU(Least Recent Used) 알고리즘
   - 최근에 가장 오랫동안 사용하지 않은 페이지를 교체하는 기법(마지막 참조시점이 가장 오래된 페이지 교체)
   - 시간지역성(temporal locality)의 성질을 고려해 고안된 알고리즘이다.
     - (시간 지역성 : 최근에 참조된 페이지가 가까운 미래에 다시 참조될 가능성이 높은 성질)
   - 계수기(Counter)나 스택(Stack)과 같은 별도의 하드웨어가 필요하며, 시간적인 오버헤드가 발생된다. (실제로 구현이 어려움)
     - (계수기 : 각 페이지별로 존재하는 논리적인 시계(Logical Clock)로, 해당 페이지가 사용될때마다 0으로 클리어 시킨 후 시간을 증가시켜 시간이 가장 오래된 페이지를 교체)
   - OPT의 경우에는 미래에 대한 예측이지만 LRU의 경우에는 과거를 보고 판단하므로 실질적으로 사용 가능한 알고리즘이라고 할 수 있다. 실제로도 최근에 사용하지 않은 페이지는 앞으로도 사용하지 않을 확률이 높다고 할 수 있다.
   - 비록 OPT 보단 페이지 결함이 더 일어날 수 있지만 실제로 사용할 수 있는 알고리즘 중에서는 좋은 방법 중 하나라고 할 수 있다.
      
      ![](https://t1.daumcdn.net/cfile/tistory/2724AE335916A04007) 

   - 문제는 어떻게 이 알고리즘을 구현하느냐는 것인데 하드웨어의 지원이 있는경우와 없는 경우가 있다.
     - 하드웨어 지원이 있는 경우
       - Counter-based
       - Stack-based
     - 하드웨어 지원이 없는 경우
       - Additional Reference Bit 알고리즘
       - Second Chance 알고리즘
       - Enhanced Second Chance 알고리즘
     - [참고1](https://dailyheumsi.tistory.com/139), [참고2](https://m.blog.naver.com/jevida/140192320825)

<br/>

3. Counting Based
   - 현재 메모리에 올라와있는 페이지들이 이전에 얼마나 참조(이용) 되었는지 그 수를 카운팅해둔다. 이 후에는 다음과 같은 2가지 알고리즘이 있다.
     - LFU (Least Frequently used) 알고리즘
       - 가장 적게 사용된 페이지를 Victim 으로 둔다.
       - 즉, 지금까지 가장 적게 사용된 페이지는 앞으로도 사용할 일이 적을 것이라고 보는 것
       - 문제는 다음과 같다.
         - 초기에 많이 사용되었지만 이후 사용되지 않는 코드가 계속 메인 메모리에 상주하게 된다는 점
         - 처음으로 교체되어 들어온 페이지가 바로 교체될 수 있다는 점
     - MFU (Most Frequently used) 알고리즘
       - 가장 많이 사용된 페이지를 Victim 으로 둔다.
       - LFU 와 반대로, 가장 많이 사용된 페이지는 앞으로 사용할 일이 적을 것이라고 보는 것
   - 둘 다 거의 사용되지 않는다.

<br/>
<br/>

## 4. 프레임 할당(Allocation of Frames)

프레임은 메인 메모리를 페이지와 같은 크기로 나눈 공간이다.
프로세스 여러개가 동시에 수행되는 상황에서 각 프로세스에게 얼마만큼의 메모리 공간을 할당할것인지를 결정해야 한다.
프로세스마다, 프레임을 기본적으로 얼마씩 할당해줘야 할까?
만약, 프로세스마다 실제로 필요한 프레임보다 너무 적게주면, Page fault 가 자주 일어날 것이고, 많이 주면, 다른 프로세스에서 Page fault 가 자주 일어날 것이다.
즉, 물리 메모리 공간은 한정적인데, 이를 어떻게 프로세스마다 잘 분배할 수 있을까?

<br/>

### 4-1. 할당 방법

1. 균등 할당
   - 그냥 모든 프로세스에 현재 가용한 물리 메모리를 균등하게 할당하는 방법
   - 예를 들어, 가용한 100개의 프레임과, 4개의 프로세스가 있을 때, 각 프로세스당 25개의 프레임을 할당하는 것.
2. 비례 할당
   - 각 프로세스 크기에 비례하여 할당하는 방법
   - 예를 들어, 가용한 100개의 프레임과, 50개 페이지로 구성된 프로세스 A, 150 페이지로 구성된 프로세스 B가 있을 경우,
   프로세스 A 에는 25개, 프로세스 B 에는 75개의 프레임을 할당하는 것.
3. 우선순위 기반 할당
   - 우선순위를 별도로 두어, 우선 순위가 높은 프로세스에 더 많은 프레임을 할당하는 방법
   - 해당 프로세스는 Page fault 가 덜 일어나, 빠르게 수행된다.



<br/>

### 4-2. Global VS Local Replacement

교체할 페이지를 선정할때, 교체 대상이 될 프레임의 범위를 어떻게 정할지에 따라 교체 방법을 전역 교체(global replacement)와 지역 교체(local replacement)로 구분할 수 있다.

1. 전역교체(Global Replacement)
   - 메모리 상의 모든 프로세스 페이지에 대한 교체 작업을 수행한다.
2. 지역교체(Local Replacement)
   - 메모리 상의 자기 자신의 프로세스 페이지에 대해서만 교체 작업을 수행한다.

다중 프로그래밍의 경우 메인 메모리에 다양한 프로세스가 동시에 올라올 수 있는데 따라서 다양한 프로세스의 페이지가 메모리에 존재하게 된다.
페이지를 교체할 때 앞의 다양한 알고리즘에 의해 victim page를 선정하게 되는데 선정하는 기준이 전체를 기준으로 하느냐 자기 프로세스의 페이지에서를 기준으로 하느냐에 대한 차이이다.
실제로 전체를 기준으로 페이지를 교체하는 Global Replacement 메모리 사용 효율이 더 좋다.

<br/>
<br/>

## 5. 스레싱(Trashing)

Thrashing 은 계속하여 Page fault 가 일어나는 현상으로, CPU excute 시간 보다 Page fault를 처리하는 I/O 시간이 더 많아질 경우를 말한다.

![](https://t1.daumcdn.net/cfile/tistory/246596495917D96707)

>한정된 자원 안에서 운영체제는 CPU의 효율성을 높이기 위해 보다 많은 프로세스를 동시에 실행시키기 위해 메모리에 많은 프로세스를 올리게 됩니다.
>
>이로써 CPU 효율성은 높아지게 됩니다. 하지만 동시에 실행 중인 프로세스의 수가 많아질수록 하나의 프로세스가 할당받는 자원의 양은 점점 적어지게 됩니다.
>
>그렇게 된다면 `할당받는 Frame의 수도 적어지게 되는데 이렇게 Frame의 수가 줄어들게 되면 그만큼 Page Fault가 많이 발생하게 되고 그렇다면 자원의 활용보다는 I/O 작업에 시간을 더욱 소비하게 됩니다.`    
>
>이렇게 되면 프로그램의 진행속도는 굉장히 느려지고 CPU의 효율성 역시 굉장히 떨어지게 됩니다.
>하지만 여기서 문제점은, `운영체제는 이러한 CPU 효율성의 저하를 극복하기 위해 메모리에 프로세스를 더욱 올리게 됩니다.`
>
>이런 악순환으로 `CPU 효율성은 기하급수적으로 떨어지게 되고` 결국에는 프로그램의 비정상적인 종료로 이어지게 되고 `이러한 현상을 Thrashing`이라고 합니다.

<br/>

쓰레싱이 발생하는 원인을 다시 정리하면 다음과 같다.
1. 멀티 프로그래밍 환경
2. **해당 프로세스가 필요로 하는 최소 프레임 개수 > 제공된 프레임 개수**

특히 2번째 원인은 우리가 어느정도 해결가능한 부분이로 '해당 프로세스에 최소 몇 개의 프레임을 주어야 하는가?'가 된다.
앞서 배운 동일 할당, 비례 할당, 우선순위 기반 할당은 정적 할당으로 한계가 뚜렷하다.

이를 해결하기 위해, 실행 중에 프레임을 할당하는 동적할당 Locality Model이 등장한다.

> Locality Model    
> 프로세스는 페이지들 마다 지역성을 가진다고 생각하는 아이디어     
> Locality는 특정한 해당 시점에서 실행 되기 위해 필요한 Page들의 집합이다.      
> 즉, 그 `Locality만큼을 담을 수 있는 Frame의 양을 할당해주면 Thrashing 현상을 막을 수 있다고 보는 것이다.`


이런 동적 할당은 Working Set Model과 Page-Fault Frequency(PFF) 두가지 방식이 존재한다.

<br/>

### 5-1. Working Set Model

![](https://user-images.githubusercontent.com/34755287/70577701-19128800-1bef-11ea-88f7-f75e6b65e063.png)

위 그래프는 프로세스가 실행 중에 어떤 프로세스를 사용하는지 표시한 것으로, 특정 시간에는 일정 범위의 페이지를 주로 참조하는 것을 알 수 있다.
이러한 성질은 캐시에서도 볼 수 있다. 이를 통해 특정 시간에 따라 사용하는 페이지의 개수만큼 프레임을 할당해줄 수 있다.

이 방법 역시 치명적인 단점이 있다. 바로 프로세스를 미리 수행해봐야 할 수 있다는 것이다. 그리고 프로세스를 수행할 때마다 사용하는 기능이 달라질 수 있으므로, Locality를 이용하는 방법은 비현실적이다.

이를 해결하기 위해 나온 것이 working set 이다. working set은 위의 locality의 방식과 유사한데, 미래가 아닌 과거를 보는 것이다.

![](https://user-images.githubusercontent.com/34755287/70577702-19ab1e80-1bef-11ea-92e2-35ce8154df64.png)

위 그림은 working set을 사용하는 모습이다. working set은 현재 시간에서 일정 시간(△) 이전동안 사용되었던 페이지의 집합이다.
△(델타)는 운영체제 내부에서 정하는 기준에 따라 다르며, 이를 working set window 라 한다. 마지막으로 working set의 개수만큼 프레임을 할당한다.

만약 현재 시간이 t1이라면 working set = {1, 2, 5, 6, 7}이다. 이 때 working set의 개수는 총 5개이므로 프레임 역시 5개를 할당해주면 된다.

<br/>

### 5-2. Page-Fault Frequency(PFF)

페이지 부재 빈도 알고리즘에서는 페이지 부재율을 주기적으로 조사하고, 이 값에 근거해서 각 프로세스에 할당할 메모리량을 조절한다.

![](https://user-images.githubusercontent.com/34755287/70577703-19ab1e80-1bef-11ea-9b8c-0d3b37805bda.png)

위 그림은 이와 같은 현상을 그래프로 나타낸 것이다. 세로축은 페이지 부재 비율이고, 가로축은 할당된 프레임의 수이다.
여기서 운영체제 내부에서 해당 프로세스의 페이지 부재 횟수를 계속 검사한다. 그러면 위와 같은 그래프처럼 나오는데, 여기서 상한선(upper bound)과 하한선(lower bound)를 설정한다.

만약 상한선보다 많은 페이지 부재가 발생하면 프레임을 더 많이 할당해주고, 하한선보다 적게 페이지 부재가 발생하면 할당된 프레임 개수를 줄여준다.

<br/>
<br/>

참고자료
- https://copycode.tistory.com/113
- https://seungahyoo.tistory.com/70
- https://jins-dev.tistory.com/entry/%EA%B0%80%EC%83%81-%EB%A9%94%EB%AA%A8%EB%A6%ACVirtual-Memory%EC%99%80-%ED%8E%98%EC%9D%B4%EC%A7%95Paging%EC%97%90-%EB%8C%80%ED%95%9C-%EC%A0%95%EB%A6%AC
- https://velog.io/@codemcd/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9COS-15.-%EA%B0%80%EC%83%81%EB%A9%94%EB%AA%A8%EB%A6%AC